# U.T. 5 A-Frame
- [U.T. 5 A-Frame](#ut-5-a-frame)
  - [El framework en profundidad](#el-framework-en-profundidad)
    - [Aprendiendo el movimiento](#aprendiendo-el-movimiento)
      - [Movimiento en la escena](#movimiento-en-la-escena)
      - [Añadiendo una cámara](#añadiendo-una-cámara)
      - [Recuperando la orientación de la cámara en Desktop](#recuperando-la-orientación-de-la-cámara-en-desktop)
      - [Recuperando el movimiento en Desktop](#recuperando-el-movimiento-en-desktop)
      - [Movimiento completo en todos los dispositivos.](#movimiento-completo-en-todos-los-dispositivos)
    - [Teoría](#teoría)
      - [Eventos](#eventos)
      - [Interación basada en la dirección de la visión con un cursor](#interación-basada-en-la-dirección-de-la-visión-con-un-cursor)
      - [Manejando los eventos con el componente event-set](#manejando-los-eventos-con-el-componente-event-set)
      - [Manejando los eventos con JavaScript](#manejando-los-eventos-con-javascript)
    - [Controladores VR](#controladores-vr)
      - [tracked-controls Component](#tracked-controls-component)
      - [Adding 3DoF Controllers (daydream-controls, gearvr-controls, oculus-go-controls)](#adding-3dof-controllers-daydream-controls-gearvr-controls-oculus-go-controls)
      - [Adding 6DoF Controllers (vive-controls, oculus-touch-controls)](#adding-6dof-controllers-vive-controls-oculus-touch-controls)
      - [Supporting Multiple Types of Controllers](#supporting-multiple-types-of-controllers)
        - [hand-controls Component](#hand-controls-component)
    - [Listening for Button and Axis Events](#listening-for-button-and-axis-events)
      - [Adding Laser Interactions for Controllers](#adding-laser-interactions-for-controllers)
      - [Adding Room Scale Interactions for Controllers](#adding-room-scale-interactions-for-controllers)


## El framework en profundidad
https://jgbarah.github.io/aframe-playground/

### Aprendiendo el movimiento
#### Movimiento en la escena
Vamos a comenzar con el movimiento básico. De momento vamos a definir la escena tipo que nos servirá de base:

>     <a-scene>
>       <a-box position="-1 0.5 -3" rotation="0 45 0" color="#4CC3D9" shadow></a-box>
>       <a-sphere position="0 1.25 -5" radius="1.25" color="#EF2D5E" shadow></a-sphere>
>       <a-cylinder position="1 0.75 -3" radius="0.5" height="1.5" color="#FFC65D" shadow></a-cylinder>
>       <a-plane position="0 0 -4" rotation="-90 0 0" width="4" height="4" color="#7BC8A4" shadow></a-plane>
>       <a-sky color="#ECECEC"></a-sky>
>     </a-scene>


- Desktop: Mover el ratón simula el movimiento de la mirada, y los cursores (or WASD) move la posición relativa del actor.

- Móviles: La orientación de la pantalla se usa para la visión, no hay manera de mover la cámara.

- Oculus Go: La orientación de las gafas se usar para orientar la visión, no hayu manera de mover la cámara.


#### Añadiendo una cámara
Curiosmanete, el hecho de añadir una cámara a la escena hará que los cursores en el Desktop y la orientación en la cámara en los dispositivos móviles dejen de funcionar.

>     <a-scene>
>       ...
>       <a-entity camera position="0 1.6 0"></a-entity>
>     </a-scene>

En el dispositivo Oculus, la orientación funciona, por aparentemente el componente de la cámara incluye la orientación en este4 caso.

En los dispositivos móviles, en el modo navegador, la escena está fija como en Desktop. Pero al entrar en VR el movimiento de la pantalla funciona como en Oculus.


#### Recuperando la orientación de la cámara en Desktop
Para esto, el primer paso es incluir el compoente look-controls:

>     <a-scene>
>       ...
>       <a-entity camera look-controls position="0 1.6 0"></a-entity>
>     </a-scene>

Ahora la escena tiene orientación en el Desktop, en dispositivos mnóviles y en Oculus.

#### Recuperando el movimiento en Desktop
Para recuperar el movimiento de la cámara en la escena usando los cursores o WASD tenemos que añadir el componente wasd-controls.

>     <a-scene>
>       ...
>       <a-entity camera look-controls wasd-controls position="0 1.6 0"></a-entity>
>     </a-scene>

Con estos cambios, la escena se controla de forma similar que en Oculus, añadiendo la posibilidad de pulsar en la pantalla de los dispositivos móviles para la acción.

#### Movimiento completo en todos los dispositivos.
Para tener el mismo comportamiento en los tres dispositivos, tenemos que añadir la posibilidad de desplazamiento a la cámara en Oculus:

Bajo Oculus, usando la mirada (la dirección en la que se está miranbdo) y el botón del contro podemos realizar accines. La mirada se usa para la dirección relativa en la que nos vamos a desplazar, el botón "cruceta" nos desplaza en las cuatro direcciones.

En el Desktop usaremos el ratón para simular la vistra y los cursores o WASD par el movimiento relativo.

Para dispositivos móviles, la orientación de la pantalla se usará para la visión y al tocar la pantalla nos podremos desplazar.

Pero para un desplazamiento total, añadiremos la librerías de extras y el compoenente movement-controls.

>     <script src="//cdn.jsdelivr.net/gh/donmccurdy/aframe-extras@v6.1.1/dist/aframe-extras.min.js"></script>

Y utilizamos dicho componente en vez de la cámara de A-Franme tradicional.

>     <a-entity movement-controls="fly: true">
>       <a-entity camera position="0 1.6 0" look-controls></a-entity>
>     </a-entity>

El componente actúa como una plataforma para la cámara. La propiedad fly permite mover la cámara arriba y abajo en el plano horizontal.Todavía es necesario especificar el control look-control para que funcione correctamente en Desktop. 


### Teoría
No hay una manera simple de añadir interacción a nuestras escenas por la cantidad de platarformas, dispositivos y métodos de entrada que A-Frame soporta. El mecanismo por escelencia de interacción es el basado en VR, en comparación con la navegación WEB 2D en la que solo nos tenemos que preocupar del ratón y de la entrada, en VR hay que controlar hasta 6 grados de movimiento.

#### Eventos
En el mundo Web 2D, la entrada y la interacción se maneja desde eventos browser. Siempre que una entrada se produce, se genera un evento que el navegador emite y puede ser recogido por un manejador para tratarlo (Element.addEventListener):

- 'click' Evento que se genera al hacer click.

>     document.querySelector('p').addEventListener('click', function (evt) {
>       console.log('This 2D element was clicked!')});

Al igual que el navegador web, A-Frame maneja los eventos y sus manejadores para la inteeracción y dinamicidad. Ya que A-Frame está basado en Javascript y todo tien como soporte final WebGL, Los eventos A-Framne son eventos personalizados que pueden ser emitidos por cualquier componente A-Frame simplemente describiéndolo:

 - 'collide' Evento generado por un comnponente como colider o algún componente físico.

>     document.querySelector('a-entity').addEventListener('collide', function (evt) {
>  console.log('This A-Frame entity collided with another entity!'); });

Uno de los principales errores es creer que podemos añadir un evento click de javascript directamente a cualquier entidad A-Frame y esperar que podemos interactuar con el ratón. En A-Frame tenemos que proporcionar la entrada y la inteacción para poder hacer clic en un objeto. Por ejemplo, A-Frame crea un componente cursor que genera un evento personalizado clic en la dirección de la visión usando un trazador de rayos.


#### Interación basada en la dirección de la visión con un cursor
La interacción con la dirección de la mirada está basada en rotar nuestra cabeza y mirar al objeto que queremos usar. Se usa para controles sin los mandos de mano. A-Frame proporciona controles por defecto basados en este mecanismo para ser usados en los Desktop para previsualizar la interacción con la cámara.

Para añidir esta interacción, necesitamos ausar o implementar un componente. A-Frame tra incorporado el componente **cursor** que proporciona toda la funcinalidad necesaria. Debe ser añadido a la cámara:

>     <a-scene>
>       <a-camera>
>         <a-cursor></a-cursor>
>         <!-- Or <a-entity cursor></a-entity> -->
>      </a-camera>
>     </a-scene>

#### Manejando los eventos con el componente event-set
A continuación nos interesa manejar los eventos que el cursor proporciona. Este componente genera eventos sintéticos similares a los de Javscript: click, mouseenter, mouseleave, mousedown, mouseup, and fusing. Aunque se llaman igual, no son los mismos, hay que gestionarlos de forma diferente.

Para el manejo básico, en el que nosotros escuchamos un evento y reaccionamos cambiando una propiedad del objeto, tenemos que usar el componente event-set. Este componente hace que la loa gestión de los evenbtos sea declarativa. El API es:


>      <a-entity event-set__${id}="_event: ${eventName}; ${someProperty}: ${toValue}">

El __\${id} nos permite unir varios componentes event-set a la misnma entidad. El parámetro ${eventName} es el evento que estamos gestionando. Y pasamos la propiedad y el valor que queremos establecer cuando se genere el mismo.

Por ejemplo, para hacer una entidad visible cuando es apuntada o mirada, al componente cursor estableceremos el siguiente código:

>     <a-entity event-set__makevisible="_event: mouseenter; visible: true">

Si queremos cambiar el color de una caja cuando pasemos por encima y restaurarlo al salir:

>      <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
>      <script src="https://unpkg.com/aframe-event-set-component@3.0.3/dist/aframe-event-set-component.min.js"></script>
>      <body>
>        <a-scene>
>          <a-box position="-1 0.5 -3" rotation="0 45 0" color="#4CC3D9"
>                event-set__enter="_event: mouseenter; color: #8FF7FF"
>                event-set__leave="_event: mouseleave; color: #4CC3D9"></a-box>
>
>          <a-camera>
>            <a-cursor></a-cursor>
>          </a-camera>
>        </a-scene>
>      </body>

El componente event-set tambien puede usar otras entidades como destino con el parámetro _target: \${selector}. Si queremos mostrar un texto cuando una entidad es apntada:

>      <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
>      <script src="https://unpkg.com/aframe-event-set-component@3.0.3/dist/aframe-event-set-component.min.js"></script>
>      <body>
>        <a-scene>
>          <a-cylinder position="1 0.75 -3" radius="0.5" height="1.5" color="#FFC65D"
>                      event-set__enter="_event: mouseenter; _target: #cylinderText; visible: true"
>                      event-set__leave="_event: mouseleave; _target: #cylinderText; visible: false">
>             <a-text id="cylinderText" value="This is a cylinder" align="center" color="#FFF" visible="false" position="0 -0.55 0.55"
>                    geometry="primitive: plane; width: 1.75" material="color: #333"></a-text>
>          </a-cylinder>
>
>          <a-camera>
>            <a-cursor></a-cursor>
>          </a-camera>
>        </a-scene>
>      </body>

Este componente también funciona con componentes que tienen varias propiedades usando la sintáxis de punto (.) para acceder (\${componentName}.\${propertyName}):

>      <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
>      <script src="https://unpkg.com/aframe-event-set-component@3.0.3/dist/aframe-event-set-component.min.js"></script>
>      <body>
>        <a-scene>
>          <a-plane position="0 0 -4" rotation="-90 0 0" width="4" height="4" color="#7BC8A4"
>                  event-set__down="_event: mousedown; material.wireframe: true"
>                  event-set__up="_event: mouseup; material.wireframe: false"
>                  event-set__leave="_event: mouseleave; material.wireframe: false"></a-plane>
>
>          <a-camera>
>            <a-cursor></a-cursor>
>          </a-camera>
>        </a-scene>
>      </body>

#### Manejando los eventos con JavaScript
El componente event-set es bueno para operaciones básicas, pero es importante saber cómo gestionar los eventos con Javascript. Cuando tenemos que hacer operaciones más complejas en respuesta a los eventos es mejor usar este método.

Para ver es uso, vamos cambiart el color de una caja al entrar y restaurarlo al salir bajo Javascript.

>      <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
>      <script>
>        AFRAME.registerComponent('change-color-on-hover', {
>          schema: {
>            color: {default: 'red'}
>          },
>
>          init: function () {
>            var data = this.data;
>            var el = this.el;  // <a-box>
>            var defaultColor = el.getAttribute('material').color;
>
>            el.addEventListener('mouseenter', function () {
>              el.setAttribute('color', data.color);
>            });
>
>            el.addEventListener('mouseleave', function () {
>              el.setAttribute('color', defaultColor);
>            });
>          }
>        });
>      </script>
>      <body>
>        <a-scene>
>          <a-box color="#EF2D5E" position="0 1 -4" change-color-on-hover="color: blue"></a-box>
>
>          <a-camera><a-cursor></a-cursor></a-camera>
>        </a-scene>
>      </body>

Tecnicamente con este mecanismo podemos hacer cualquier cosa ya que tenemos acceso completo a Javascript, three.js y todas las WEB APIS.

### Controladores VR
Controllers are vital for immersing people into a VR application. The potential of VR is not met without them, namely controllers that provide six degrees of freedom (6DoF). With controllers, people can reach out and around the scene and interact with objects with their hands.

A-Frame provides components for controllers across the spectrum as supported by their respective WebVR browsers through the Gamepad Web API. There are components for Vive, Oculus Touch, Daydream, GearVR and Oculus Go controllers.

To inspect the Gamepad object for poking around or to get the Gamepad ID, we can call navigator.getGamepads() in the browser console. This will return a GamepadList array with all of the connected controllers.

For advanced applications, controllers are built and tailored for the application (i.e., custom 3D models, animations, mappings, gestures). For example, a medieval knight might have metal gauntlets, or a robot might have a robot hand that can shoot lasers or display information on the wrist.

The controller components that A-Frame provide primarily act as defaults, starter components, or a base from which to derive more custom controller components.

#### tracked-controls Component
The tracked-controls component is A-Frame’s base controller component that provides the foundation for all of A-Frame’s controller components. The tracked-controls component:

Grabs a Gamepad object from the Gamepad API given an ID or prefix.
Applies pose (position and orientation) from the Gamepad API to read controller motion.
Looks for changes in the Gamepad object’s button values to provide events when buttons are pressed or touched and when axis and touchpads are changed (i.e., axischanged, buttonchanged, buttondown, buttonup, touchstart, touchend).
All of A-Frame’s controller components build on top of the tracked-controls component by:

Setting the tracked-controls component on the entity with the appropriate Gamepad ID (e.g., Oculus Touch (Right)). For example, the vive-controls component does el.setAttribute('tracked-controls', {idPrefix: 'OpenVR'}). tracked-controls will then connect to the appropriate Gamepad object to provide pose and events for the entity.
Abstracting the events provided by tracked-controls. tracked-controls events are low-level; it’d difficult for us to tell which buttons were pressed based off of those events alone because we’d have to know the button mappings beforehand. Controller components can know the mappings beforehand for their respective controllers and provide more semantic events such as triggerdown or xbuttonup.
Providing a model. tracked-controls alone does not provide any appearance. Controller components can provide a model that shows visual feedback, gestures, and animations when buttons are pressed or touched.
The controller components following are only activated if they detect the controller is found and seen as connected in the Gamepad API.

#### Adding 3DoF Controllers (daydream-controls, gearvr-controls, oculus-go-controls)
Controllers with 3 degrees of freedom (3DoF) are limited to rotational tracking. 3DoF controllers have no positional tracking meaning we can’t reach out nor move our hand back-and-forth or up-and-down. Having a controller with only 3DoF is like having a hand and wrist without an arm. Read more about degrees of freedom for VR.

The 3DoF controller components provide rotational tracking, a default model matching the real-life hardware, and events to abstract the button mappings. The controllers for Google Daydream, Samsung GearVR and Oculus Go have 3DoF, and both support only one controller for one hand.

To add a controller for Google Daydream, use the daydream-controls component. Then try it out on Chrome for Android on a Daydream smartphone:

      <a-entity daydream-controls></a-entity>
To add a controller for Samsung GearVR, use the gearvr-controls component. Then try it out on Oculus Carmel or Samsung Internet on a smartphone with GearVR:

      <a-entity gearvr-controls></a-entity>
To add a controller for Oculus Go, use the oculus-go-controls component. Then try it out on Oculus Browser or Samsung Internet on an Oculus Go standalone headset:

      <a-entity oculus-go-controls></a-entity>

#### Adding 6DoF Controllers (vive-controls, oculus-touch-controls)
Controllers with 6 degrees of freedom (6DoF) have both rotational and positional tracking. Unlike controllers with 3DoF which are constrained to orientation, controllers with 6DoF are able to move freely in 3D space. 6DoF allows us to reach forward, behind our backs, move our hands across our body or close to our face. Having 6DoF is like reality where we have both hands and arms. 6DoF also applies to the headset and additional trackers (e.g., feet, props). Having 6DoF is a minimum for providing a truly immersive VR experience.

The 6DoF controller components provide full tracking, a default model matching the real-life hardware, and events to abstract the button mappings. HTC Vive and Oculus Rift with Touch provide 6DoF and controllers for both hands. HTC Vive also provides trackers for tracking additional objects in the real world into VR.

To add controllers for HTC Vive, use the vive-controls component for both hands. Then try it out on a WebVR-enabled desktop browser:

      <a-entity vive-controls="hand: left"></a-entity>
      <a-entity vive-controls="hand: right"></a-entity>
To add controllers for Oculus Touch, use the oculus-touch-controls component for both hands. Then try it out on a WebVR-enabled desktop browser:

      <a-entity oculus-touch-controls="hand: left"></a-entity>
      <a-entity oculus-touch-controls="hand: right"></a-entity>
#### Supporting Multiple Types of Controllers
The Web has the benefit of being able to support multiple platforms. Though it’s less clear in VR what supporting multiple platforms entails since a 3DoF platform versus a 6DoF platform provide different interactions and require different user experience treatment. It will be up to the application what “responsive” means for VR on the Web. What we can show are several different methods, but none that are truly one-size-fits-all.

##### hand-controls Component
A-Frame provides an implementation for supporting multiple types of 6DoF controllers (Vive, Oculus Touch) via the hand-controls component. The hand-controls component is primarily for 6DoF controllers since it’s geared towards room scale interactions such as grabbing objects. The hand-controls component works on top of both Vive and Oculus Touch controllers by:

Setting both the vive-controls and oculus-touch-controls component
Overriding the controller models with a simple hand model
Mapping Vive-specific and Oculus Touch-specific events to hand events and gestures (e.g., gripdown and triggerdown to thumbup)
To add the hand-controls component:

      <a-entity hand-controls="left"></a-entity>
      <a-entity hand-controls="right"></a-entity>
Unfortunately, there is not yet a 3DoF controller component that abstracts well all the types of 3DoF controllers (i.e., Daydream, GearVR). We could create a custom controller that works with both controllers. It would be fairly easy to cover since 3DoF controllers do not offer much potential for interaction (i.e., only rotational tracking with a touchpad).

However, there is a controller component that covers all 6DoF and 3DoF controllers currently supported by A-Frame: laser-controls.


### Listening for Button and Axis Events
Controllers have many buttons and emit many events. For each button, every time a button is pressed down, released, or for some cases, even touched. And for each axis (e.g., trackpad, thumbstick), an event is emitted every time it is touched. To handle buttons, look for the event name in the respective controller component documentation pages at the event tables, then register event handlers how we want:

daydream-controls events
gearvr-controls events
hand-controls events
oculus-touch-controls events
vive-controls events
windows-motion-controls events
For example, we can listen to the Oculus Touch X button press, and toggle visibility of an entity. In component form:

      AFRAME.registerComponent('x-button-listener', {
        init: function () {
          var el = this.el;
          el.addEventListener('xbuttondown', function (evt) {
            el.setAttribute('visible', !el.getAttribute('visible'));
          });
        }
      });
Then attach the component:

      <a-entity oculus-touch-controls x-button-listener></a-entity>
#### Adding Laser Interactions for Controllers
Laser interactions refer to placing a visible raycaster (line) shooting out of the controller. Interactions occur when entities intersect the line, a controller button changes during intersection, and/or when entities no longer intersect the line. This interaction is very similar to gaze-based interaction, except the raycaster is now affixed to the controller rather than the headset.

The laser-controls component component provides laser interactions for controllers. The usage is almost exactly similar to the cursor component, but attach the component to the controller rather than under the camera:

      <a-entity laser-controls="hand: right"></a-entity>
Then default length of the laser is configured by adjusting the length of the raycaster. When the laser intersects with an entity, the length of the laser will be truncated.

      <a-entity hand-controls laser-controls raycaster="far: 2"></a-entity>
Then handling events and interactions is the exact same as gaze-based interactions with the cursor component . Refer to the section above!

#### Adding Room Scale Interactions for Controllers
Room scale interactions are harder. These include interactions in 3D space and two-handed interactions such as grabbing, throwing, stretching, hitting, turning, pulling, or pushing. The number or complexity of room scale interactions is not something we can completely cover. This is unlike the 2D Web where there is just mouse and touchscreen or 3DoF VR where there is only wiggling the controller. But we can show various implementations that can be used as is or as a reference.

Rather than using raycasters to detect for intersections with objects, room scale and 3D interactions involve colliders. Whereas raycasters are 2D lines, colliders are 3D volumes. There are different shapes of colliders (AABB/box, sphere, mesh) that wrap around objects, and when those shapes intersect, a collision is detected.

super-hands Component
The super-hands component by William Murphy provides all-in-one natural hand controller interaction. The component interprets input from tracked controllers and collision detection components into interaction gestures and communicates those gestures to target entities for them to respond.

The currently implemented gestures are:

Hover: Holding a controller in the collision space of an entity
Grab: Pressing a button while hovering an entity, potentially also moving it
Stretch: Grabbing an entity with two hands and resizing
Drag-drop: Dragging an entity onto another entity
For an entity to respond to the super-hands gestures, the entity needs to have components attached to translate the gestures into actions. super-hands includes components for typical reactions to the implemented gestures: hoverable, grabbable, stretchable, and drag-droppable.


---
[Siguiente](ut_5_06.md)
